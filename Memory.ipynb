{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalhando com o processo de memorização dos modelos de LLM para construção de chatbots que armazenam informações sobre o usuário ao qual está conversando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Bibliotecas\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando API KEY da OpenAI diretamente da minha variável de ambiente .env\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Selecionando Modelo de LLM da OpenAI\n",
    "llm_model = \"gpt-4o-mini\"\n",
    "model = ChatOpenAI(model=llm_model, temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = model,\n",
    "    memory = memory,\n",
    "    #A verbosidade mostra alguns prompts que o modelo está recebendo\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá, meu nome é Diogo\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Olá, meu nome é Diogo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Diogo\n",
      "AI: Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?\n",
      "Human: Qual meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Diogo! Como posso ajudar você hoje, Diogo?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Qual meu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Diogo\n",
      "AI: Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?\n",
      "Human: Qual meu nome?\n",
      "AI: Seu nome é Diogo! Como posso ajudar você hoje, Diogo?\n",
      "Human: Eu tenho dois gatinhos, um macho e uma fêmea. O macho se chama Rengar, em homenagem\n",
      "                     a um personagem de league of legends, a fêmea se chama KillJoy, em homenagem a personagem\n",
      "                     de Valorant!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Que nomes incríveis para os seus gatinhos, Diogo! Rengar é um personagem bem interessante de League of Legends, conhecido por sua natureza feroz e habilidades de caça. E KillJoy, de Valorant, é uma personagem muito inteligente e cheia de gadgets! Como eles estão se saindo? Eles têm personalidades diferentes?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"\"\"Eu tenho dois gatinhos, um macho e uma fêmea. O macho se chama Rengar, em homenagem\n",
    "                     a um personagem de league of legends, a fêmea se chama KillJoy, em homenagem a personagem\n",
    "                     de Valorant!\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Diogo\n",
      "AI: Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?\n",
      "Human: Qual meu nome?\n",
      "AI: Seu nome é Diogo! Como posso ajudar você hoje, Diogo?\n",
      "Human: Eu tenho dois gatinhos, um macho e uma fêmea. O macho se chama Rengar, em homenagem\n",
      "                     a um personagem de league of legends, a fêmea se chama KillJoy, em homenagem a personagem\n",
      "                     de Valorant!\n",
      "AI: Que nomes incríveis para os seus gatinhos, Diogo! Rengar é um personagem bem interessante de League of Legends, conhecido por sua natureza feroz e habilidades de caça. E KillJoy, de Valorant, é uma personagem muito inteligente e cheia de gadgets! Como eles estão se saindo? Eles têm personalidades diferentes?\n",
      "Human: Qual nome do meu gato macho e por que?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O nome do seu gato macho é Rengar, em homenagem ao personagem de League of Legends. Rengar é conhecido por ser um caçador astuto e feroz, o que é uma ótima inspiração para um gato! Como ele se comporta? Ele é tão aventureiro quanto o personagem?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"\"\"Qual nome do meu gato macho e por que?\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Olá, meu nome é Diogo\\nAI: Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?\\nHuman: Qual meu nome?\\nAI: Seu nome é Diogo! Como posso ajudar você hoje, Diogo?\\nHuman: Eu tenho dois gatinhos, um macho e uma fêmea. O macho se chama Rengar, em homenagem\\n                     a um personagem de league of legends, a fêmea se chama KillJoy, em homenagem a personagem\\n                     de Valorant!\\nAI: Que nomes incríveis para os seus gatinhos, Diogo! Rengar é um personagem bem interessante de League of Legends, conhecido por sua natureza feroz e habilidades de caça. E KillJoy, de Valorant, é uma personagem muito inteligente e cheia de gadgets! Como eles estão se saindo? Eles têm personalidades diferentes?\\nHuman: Qual nome do meu gato macho e por que?\\nAI: O nome do seu gato macho é Rengar, em homenagem ao personagem de League of Legends. Rengar é conhecido por ser um caçador astuto e feroz, o que é uma ótima inspiração para um gato! Como ele se comporta? Ele é tão aventureiro quanto o personagem?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Armazena todo o histórico da conversa entre o humano e o chat\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Olá, meu nome é Diogo\\nAI: Olá, Diogo! É um prazer te conhecer! Como você está hoje? Tem algo específico em mente que gostaria de conversar ou perguntar?\\nHuman: Qual meu nome?\\nAI: Seu nome é Diogo! Como posso ajudar você hoje, Diogo?\\nHuman: Eu tenho dois gatinhos, um macho e uma fêmea. O macho se chama Rengar, em homenagem\\n                     a um personagem de league of legends, a fêmea se chama KillJoy, em homenagem a personagem\\n                     de Valorant!\\nAI: Que nomes incríveis para os seus gatinhos, Diogo! Rengar é um personagem bem interessante de League of Legends, conhecido por sua natureza feroz e habilidades de caça. E KillJoy, de Valorant, é uma personagem muito inteligente e cheia de gadgets! Como eles estão se saindo? Eles têm personalidades diferentes?\\nHuman: Qual nome do meu gato macho e por que?\\nAI: O nome do seu gato macho é Rengar, em homenagem ao personagem de League of Legends. Rengar é conhecido por ser um caçador astuto e feroz, o que é uma ótima inspiração para um gato! Como ele se comporta? Ele é tão aventureiro quanto o personagem?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Opa!\"}, {\"output\":\"Eaí, tranquilo?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Opa!\\nAI: Eaí, tranquilo?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Opa!\\nAI: Eaí, tranquilo?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"O que tem feito de bom?\"}, {\"output\":\"Sou uma inteligência artificial, o que você acha?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Opa!\\nAI: Eaí, tranquilo?\\nHuman: O que tem feito de bom?\\nAI: Sou uma inteligência artificial, o que você acha?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Buffer Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k basicamente é a quantidade de blocos de conversa que o modelo irá lembrar, por ex 1, ele lembrará apenas\n",
    "# do ultimo input/output do modelo, quanto maior k, maior a memória\n",
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Opa!\"}, {\"output\":\"Eaí, tranquilo?\"})\n",
    "memory.save_context({\"input\":\"O que tem feito de bom?\"}, {\"output\":\"Sou uma inteligência artificial, o que você acha?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: O que tem feito de bom?\\nAI: Sou uma inteligência artificial, o que você acha?'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm = model,\n",
    "    memory = memory,\n",
    "    #A verbosidade mostra alguns prompts que o modelo está recebendo\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá, meu nome é Diogo, tudo bem?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Diogo! Tudo bem, obrigado por perguntar! Estou aqui para ajudar e conversar. Como você está hoje? Tem algo específico em mente que gostaria de discutir?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Olá, meu nome é Diogo, tudo bem?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Diogo, tudo bem?\n",
      "AI: Olá, Diogo! Tudo bem, obrigado por perguntar! Estou aqui para ajudar e conversar. Como você está hoje? Tem algo específico em mente que gostaria de discutir?\n",
      "Human: Que ótimo, hoje fui ao cinema e você o que faz de bom?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Que legal que você foi ao cinema! Qual filme você assistiu? Eu, como uma inteligência artificial, não vou ao cinema, mas adoro conversar sobre filmes e suas histórias. Posso te ajudar a encontrar informações sobre filmes, discutir enredos ou até mesmo recomendar alguns! O que você achou do filme que viu?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Que ótimo, hoje fui ao cinema e você o que faz de bom?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Que ótimo, hoje fui ao cinema e você o que faz de bom?\n",
      "AI: Que legal que você foi ao cinema! Qual filme você assistiu? Eu, como uma inteligência artificial, não vou ao cinema, mas adoro conversar sobre filmes e suas histórias. Posso te ajudar a encontrar informações sobre filmes, discutir enredos ou até mesmo recomendar alguns! O que você achou do filme que viu?\n",
      "Human: Qual meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas eu não sei qual é o seu nome. Se você quiser, pode me contar! Estou aqui para conversar e ajudar no que precisar.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Qual meu nome?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "planejamento = \"\"\"Acordar as seis da manhã,\n",
    "tomar um cafézinho rapido, \n",
    "correr para ajudar a começar o dia bem, \n",
    "as 8 começar o trabalho do dia,\n",
    "comparecer a daily as 9 da manhã, \n",
    "após, continuar o trabalho,\n",
    "ir até o meio dia e almoçar\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=model, max_token_limit=50)\n",
    "memory.save_context({\"input\":\"Olá chat!\"}, {\"output\":\"Eaí? Como vai? Em que posso ajudar?\"})\n",
    "memory.save_context({\"input\":\"Qual meu planejamento para hoje?\"}, {\"output\":f\"{planejamento}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI, and the AI responds warmly, asking how it can help. The human inquires about their planning for the day, and the AI outlines a schedule that includes waking up at six, having a quick coffee, starting the day positively, beginning work at eight, attending a daily meeting at nine, continuing work until noon, and then having lunch.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O modelo fez uma sumarização de tudo que aconteceu no bate-papo. \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Token Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando o modelo identificar que a memória possui mais de 50 tokens,\n",
    "# Ele vai ignorar uma certa parte do conteúdo da memória \n",
    "memory = ConversationTokenBufferMemory(llm=model, max_token_limit=50)\n",
    "memory.save_context({\"input\":\"Olá chat!\"}, {\"output\":\"Eaí? Como vai? Em que posso ajudar?\"})\n",
    "memory.save_context({\"input\":\"Qual o ponto turístico mais popular de João Pessoa?\"}, {\"output\":\"Lagoa\"})\n",
    "memory.save_context({\"input\":\"E um lugar para passar um tempo numa tarde de sábado?\"}, {\"output\":\"Sabadinho bom\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Qual o ponto turístico mais popular de João Pessoa?\\nAI: Lagoa\\nHuman: E um lugar para passar um tempo numa tarde de sábado?\\nAI: Sabadinho bom'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
