{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompt Templates e Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Bibliotecas\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando API KEY da OpenAI diretamente da minha variável de ambiente .env\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Selecionando Modelo de LLM da OpenAI\n",
    "llm_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhando SEM o langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável por receber o prompt e processar resposta baseada nele.\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, estou trabalhando de forma \"crua\", sem o framework.\n",
    "\n",
    "A ideia é fazer o modelo traduzir a minha apresentação pessoal para outro idioma, o inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobre_mim = \"\"\"Olá! Meu nome é Diogo Dias, sou estudante de \\\n",
    "Engenharia pela Universidade Federal da Paraíba (UFPB) e facinado por \\\n",
    "tudo que envolve dados e inteligência artificial. \\\n",
    "Estou trabalhando para que em breve eu consiga reopcionar meu curso \\\n",
    "para Ciência de Dados e IA na própria UFPB, porém, enquanto isso não acontece, \\\n",
    "faço uma graduação à distância em Ciência de Dados pela Cruzeiro do Sul Virtual. \\\n",
    "Seria legal te conhecer também! Entra em contato comigo pelo meu Discord para \\\n",
    "trocarmos uma idéia ;) meu nick é azafama!\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traducao = \"\"\"Inglês do UK\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduza o texto de apresentação pessoal destacado pelas três aspas invertidas para o seguinte idioma Inglês do UK.\n",
      "texto: ```Olá! Meu nome é Diogo Dias, sou estudante de Engenharia pela Universidade Federal da Paraíba (UFPB) e facinado por tudo que envolve dados e inteligência artificial. Estou trabalhando para que em breve eu consiga reopcionar meu curso para Ciência de Dados e IA na própria UFPB, porém, enquanto isso não acontece, faço uma graduação à distância em Ciência de Dados pela Cruzeiro do Sul Virtual. Seria legal te conhecer também! Entra em contato comigo pelo meu Discord para trocarmos uma idéia ;) meu nick é azafama!```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Traduza o texto de apresentação pessoal \\\n",
    "destacado pelas três aspas invertidas \\\n",
    "para o seguinte idioma {traducao}.\n",
    "texto: ```{sobre_mim}```\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s the translation of your text into UK English:\n",
      "\n",
      "```Hello! My name is Diogo Dias, I am a student of Engineering at the Federal University of Paraíba (UFPB) and I am fascinated by everything that involves data and artificial intelligence. I am working towards the goal of soon being able to switch my course to Data Science and AI at UFPB itself; however, while that is not happening, I am pursuing a distance learning degree in Data Science at Cruzeiro do Sul Virtual. It would be great to meet you too! Get in touch with me on my Discord so we can have a chat ;) my username is azafama!```\n"
     ]
    }
   ],
   "source": [
    "resposta = get_completion(prompt)\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacote do LangChain para modelos da OpenAI (seguindo a documentação)\n",
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando biblioteca do langchain para trabalhar com modelos da OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo o modelo\n",
    "# Temperatura pode variar de 0 a 1, isso afeta a forma com que o modelo trás as respostas. \n",
    "# Para uma resposta mais replicável, 0.0 é o ideal.\n",
    "model = ChatOpenAI(model=llm_model, temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia é fazer com que prompts consigam ser componentizados para ser reaproveitados no código. A biblioteca por padrão possui alguns templates, mas, é possível realizar a criação dos próprios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repare que aqui não estou usando o (f) antes das aspas para formatar a string, \n",
    "# se eu adicionar (f) as variáveis (traducao, sobre_mim) não serão reconhecidas como variáveis no template_string\n",
    "template_string = \"\"\"Traduza o texto de apresentação pessoal \\\n",
    "destacado pelas três aspas invertidas \\\n",
    "para o seguinte idioma {traducao}.\n",
    "texto: ```{sobre_mim}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Criando meu Prompt Template\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['sobre_mim', 'traducao'], template='Traduza o texto de apresentação pessoal destacado pelas três aspas invertidas para o seguinte idioma {traducao}.\\ntexto: ```{sobre_mim}```')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraindo o conteúdo do meu prompt Template.\n",
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar as variáveis de input quando se printa o prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sobre_mim', 'traducao']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando apenas minhas variáveis do prompt_template\n",
    "prompt_template.messages[0].input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idioma = \"\"\"Inglês do UK\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "apresentacao = \"\"\"Olá! Meu nome é Diogo Dias, sou estudante de \\\n",
    "Engenharia pela Universidade Federal da Paraíba (UFPB) e facinado por \\\n",
    "tudo que envolve dados e inteligência artificial. \\\n",
    "Estou trabalhando para que em breve eu consiga reopcionar meu curso \\\n",
    "para Ciência de Dados e IA na própria UFPB, porém, enquanto isso não acontece, \\\n",
    "faço uma graduação à distância em Ciência de Dados pela Cruzeiro do Sul Virtual. \\\n",
    "Seria legal te conhecer também! Entra em contato comigo pelo meu Discord para \\\n",
    "trocarmos uma idéia ;) meu nick é azafama!\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputando valores as variáveis do prompt template\n",
    "apresentacao_pessoal = prompt_template.format_messages(\n",
    "    sobre_mim = apresentacao,\n",
    "    traducao = idioma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(apresentacao_pessoal))\n",
    "print(type(apresentacao_pessoal[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Traduza o texto de apresentação pessoal destacado pelas três aspas invertidas para o seguinte idioma Inglês do UK.\\ntexto: ```Olá! Meu nome é Diogo Dias, sou estudante de Engenharia pela Universidade Federal da Paraíba (UFPB) e facinado por tudo que envolve dados e inteligência artificial. Estou trabalhando para que em breve eu consiga reopcionar meu curso para Ciência de Dados e IA na própria UFPB, porém, enquanto isso não acontece, faço uma graduação à distância em Ciência de Dados pela Cruzeiro do Sul Virtual. Seria legal te conhecer também! Entra em contato comigo pelo meu Discord para trocarmos uma idéia ;) meu nick é azafama!```'\n"
     ]
    }
   ],
   "source": [
    "print(apresentacao_pessoal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diasd\\anaconda3\\envs\\ChatBot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "resposta_langchain = model(apresentacao_pessoal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Sure! Here’s the translation of your text into UK English:\\n\\n```Hello! My name is Diogo Dias, I am a student of Engineering at the Federal University of Paraíba (UFPB) and I am fascinated by everything that involves data and artificial intelligence. I am working towards the goal of soon being able to switch my course to Data Science and AI at UFPB itself; however, while that is not happening, I am pursuing a distance learning degree in Data Science at Cruzeiro do Sul Virtual. It would be great to meet you too! Get in touch with me on my Discord so we can have a chat ;) my username is azafama!```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 149, 'total_tokens': 285}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8080d70943', 'finish_reason': 'stop', 'logprobs': None} id='run-cbd2aa9a-4bbe-4232-b24f-5781910703dc-0' usage_metadata={'input_tokens': 149, 'output_tokens': 136, 'total_tokens': 285}\n"
     ]
    }
   ],
   "source": [
    "# Printar o retorno completo do modelo com langchain, mostra algumas curiosidades como tokens, e outros.\n",
    "print(resposta_langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s the translation of your text into UK English:\n",
      "\n",
      "```Hello! My name is Diogo Dias, I am a student of Engineering at the Federal University of Paraíba (UFPB) and I am fascinated by everything that involves data and artificial intelligence. I am working towards the goal of soon being able to switch my course to Data Science and AI at UFPB itself; however, while that is not happening, I am pursuing a distance learning degree in Data Science at Cruzeiro do Sul Virtual. It would be great to meet you too! Get in touch with me on my Discord so we can have a chat ;) my username is azafama!```\n"
     ]
    }
   ],
   "source": [
    "print(resposta_langchain.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Parsers são usadas para processar a saída gerada pelo LLM para convertê-la em um formato mais útil ou estruturado.\n",
    "\n",
    "Útil quando é preciso estruturar os dados para utilização em outras aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Sem output parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ração': 'xanin', 'tempo_de_entrega': 3, 'preco': 'Em conta!'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"ração\": \"xanin\",\n",
    "    \"tempo_de_entrega\": 3,\n",
    "    \"preco\": \"Em conta!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_cliente = \"\"\"Comprei a ração whiskas para meu gato no estabelecimento \\\n",
    "infelizmente ele não se adaptou muito bem. Demorou bastante pra chegar aqui em casa, \\\n",
    "fiquei espantado, o estebelecimento é na cidade vizinha e levou uns dois dias para entregar! Absurdo! \\\n",
    "Sem contar que o preço é bem salgado, muito caro, se não houver melhora no serviço \\\n",
    "irei trocar de loja!\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_feedback = \"\"\"\\\n",
    "\n",
    "para o texto a seguir, extraia as informações: \\\n",
    "\n",
    "ração: o nome da marca da ração para animais descrita no texto. Caso não houver um nome de marca \\\n",
    "adicione um None.\n",
    "\n",
    "tempo_de_entrega: a quantidade o tempo que o cliente esperou para realização \\\n",
    "da entrega. Caso a quantidade de tempo tenha sido escrita, coverta em número.\n",
    "\n",
    "preco: classifique como satisfatório ou caro, de acordo com a análise do feedback do cliente.\n",
    "\n",
    "formate essas informações em um JSON com as seguintes chaves:\n",
    "\n",
    "racao\n",
    "tempo_de_entrega\n",
    "preco\n",
    "\n",
    "texto: {feedback_cliente}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['feedback_cliente'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['feedback_cliente'], template='\\npara o texto a seguir, extraia as informações: \\nração: o nome da marca da ração para animais descrita no texto. Caso não houver um nome de marca adicione um None.\\n\\ntempo_de_entrega: a quantidade o tempo que o cliente esperou para realização da entrega. Caso a quantidade de tempo tenha sido escrita, coverta em número.\\n\\npreco: classifique como satisfatório ou caro, de acordo com a análise do feedback do cliente.\\n\\nformate essas informações em um JSON com as seguintes chaves:\\n\\nracao\\ntempo_de_entrega\\npreco\\n\\ntexto: {feedback_cliente}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template_feedback)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"racao\": \"whiskas\",\n",
      "  \"tempo_de_entrega\": 2,\n",
      "  \"preco\": \"caro\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(feedback_cliente=feedback_cliente)\n",
    "resposta = model(messages)\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# O tipo da resposta sem o parse é string, ou seja, preciso converter para\n",
    "# um formato onde seja possível a utilização em uma aplicação!\n",
    "# é aqui onde entram os parses.\n",
    "print(type(resposta.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando ferramentas de parse\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos Schemas\n",
    "racao_schema = ResponseSchema(name=\"racao\",\n",
    "                              description=\"A ração foi comprada para algum animal? \\\n",
    "                                responda com o nome da marca se sim, ou None se não.\")\n",
    "\n",
    "tempo_de_entrega_schema = ResponseSchema(name=\"tempo_de_entrega\",\n",
    "                                         description=\"Quantos dias levou para que o item fosse entregue \\\n",
    "                                          Se o dia for escrito, converta para número. Se a informação não for \\\n",
    "                                            encontrada, retorne -1\")\n",
    "\n",
    "preco_schema = ResponseSchema(name=\"preco\",\n",
    "                              description=\"Classifique o preço como caro ou acessível \\\n",
    "                                de acordo com a descrição do usuário. Retorne 'não informado' para feedback \\\n",
    "                                  de preço não informado.\") \n",
    "\n",
    "response_schema = [racao_schema,\n",
    "                   tempo_de_entrega_schema,\n",
    "                   preco_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estruturando a saída através dos schemas \n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format_messages(feedback_cliente=feedback_cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = model(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com base na estrutura passada para a variável output_parser, \n",
    "# é possível extrair o conteúdo da resposta do modelo \n",
    "# e moldar para uma saída filtrada.\n",
    "structured_output = output_parser.parse(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'racao': 'whiskas', 'tempo_de_entrega': 2, 'preco': 'caro'}\n"
     ]
    }
   ],
   "source": [
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Agora o tipo do dado foi convertido a dicionário\n",
    "print(type(structured_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whiskas'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_output.get(\"racao\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
